{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "65b799ff3037c73825aaeb240ff2a5e5f1c71043747e7ea33a3e442c1e39c7ca"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#Formatting xml file with links\n",
    "This notebok has a very simple functionality, providing formatting of xml file from tora.ws open source site of jewish holy texts to much prettyfied json format for the future mining of jewish text data from this site."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import json\n",
    "import xmltodict\n",
    "import requests\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we declare our constants:\n",
    "#Base Url, which contains all the links to files with jewish text from tora.ws\n",
    "BASE_URL = 'http://mobile.tora.ws/xml/tanach.xml'\n",
    "#Headers for http request\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xmltodict.parse(requests.get(BASE_URL, headers = HEADERS).content.decode('utf-8', 'ignore'))\n",
    "data = data['index']['node'][1:]\n",
    "links = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that normalizes the input @data and pushes it in to @target dict\n",
    "def normalize(data, target):\n",
    "    if type(data) == list:\n",
    "        for item in data:\n",
    "            tmp = dict()\n",
    "            normalize(item, tmp)\n",
    "            target.update(tmp)\n",
    "    elif type(data) == OrderedDict:\n",
    "        name = data['@name']\n",
    "        target[name] = dict()\n",
    "        if 'node' in data.keys():\n",
    "            node = data['node']\n",
    "            normalize(node, target[name])\n",
    "        else:\n",
    "            for item in data:\n",
    "                if item == '@name': continue\n",
    "                target[name][item[1:]] = data[item]\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(data, links)\n",
    "with open('links.json', 'w', encoding = 'utf-8') as file:\n",
    "    json.dump(links, file, indent = 4, ensure_ascii = False)"
   ]
  }
 ]
}